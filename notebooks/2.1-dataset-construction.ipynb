{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: portalocker in d:\\code\\venvs\\rl\\lib\\site-packages (2.8.2)\n",
      "Requirement already satisfied: pywin32>=226 in d:\\code\\venvs\\rl\\lib\\site-packages (from portalocker) (306)\n"
     ]
    }
   ],
   "source": [
    "!pip install portalocker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from torchtext.datasets import AG_NEWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_sentences)=120000\n",
      "len(test_sentences)=7600\n"
     ]
    }
   ],
   "source": [
    "train_dataset = to_map_style_dataset(AG_NEWS(root=\"../data\", split=\"train\"))\n",
    "test_dataset = to_map_style_dataset(AG_NEWS(root=\"../data\", split=\"test\"))\n",
    "\n",
    "train_sentences = [x[1] for x in train_dataset]\n",
    "test_sentences = [x[1] for x in test_dataset]\n",
    "\n",
    "print(f\"{len(train_sentences)=}\")\n",
    "print(f\"{len(test_sentences)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\", 'Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,\\\\which has a reputation for making well-timed and occasionally\\\\controversial plays in the defense industry, has quietly placed\\\\its bets on another part of the market.', \"Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\\\about the economy and the outlook for earnings are expected to\\\\hang over the stock market next week during the depth of the\\\\summer doldrums.\", 'Iraq Halts Oil Exports from Main Southern Pipeline (Reuters) Reuters - Authorities have halted oil export\\\\flows from the main pipeline in southern Iraq after\\\\intelligence showed a rebel militia could strike\\\\infrastructure, an oil official said on Saturday.', 'Oil prices soar to all-time record, posing new menace to US economy (AFP) AFP - Tearaway world oil prices, toppling records and straining wallets, present a new economic menace barely three months before the US presidential elections.']\n"
     ]
    }
   ],
   "source": [
    "print(train_sentences[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "RetryProviderError",
     "evalue": "RetryProvider failed:\nChatgpt4Online: NestAsyncioError: Use \"create_async\" instead of \"create\" function in a running event loop. Or use \"nest_asyncio\" package.\nYou: NestAsyncioError: Use \"create_async\" instead of \"create\" function in a running event loop. Or use \"nest_asyncio\" package.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRetryProviderError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mg4f\u001b[39;00m\n\u001b[0;32m      3\u001b[0m response \u001b[38;5;241m=\u001b[39m g4f\u001b[38;5;241m.\u001b[39mChatCompletion\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m      4\u001b[0m   model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m   messages\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mКакова площадь австралии\u001b[39m\u001b[38;5;124m\"\u001b[39m}],\n\u001b[0;32m      6\u001b[0m   stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      7\u001b[0m )\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflush\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Code\\venvs\\rl\\Lib\\site-packages\\g4f\\providers\\retry_provider.py:81\u001b[0m, in \u001b[0;36mRetryProvider.create_completion\u001b[1;34m(self, model, messages, stream, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m started:\n\u001b[0;32m     79\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m---> 81\u001b[0m \u001b[43mraise_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexceptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Code\\venvs\\rl\\Lib\\site-packages\\g4f\\providers\\retry_provider.py:201\u001b[0m, in \u001b[0;36mraise_exceptions\u001b[1;34m(exceptions)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03mRaise a combined exception if any occurred during retries.\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03m    RetryNoProviderError: If no provider is found.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exceptions:\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RetryProviderError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryProvider failed:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p, exception \u001b[38;5;129;01min\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    203\u001b[0m     ]))\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m RetryNoProviderError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo provider found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRetryProviderError\u001b[0m: RetryProvider failed:\nChatgpt4Online: NestAsyncioError: Use \"create_async\" instead of \"create\" function in a running event loop. Or use \"nest_asyncio\" package.\nYou: NestAsyncioError: Use \"create_async\" instead of \"create\" function in a running event loop. Or use \"nest_asyncio\" package."
     ]
    }
   ],
   "source": [
    "import g4f\n",
    "\n",
    "response = g4f.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[{\"role\":\"user\", \"content\": \"Какова площадь австралии\"}],\n",
    "  stream=True,\n",
    ")\n",
    "\n",
    "for msg in response:\n",
    "  print(msg, flush=True,end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\venvs\\rl\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at tuner007/pegasus_paraphrase and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "\n",
    "model_name = \"tuner007/pegasus_paraphrase\"\n",
    "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
    "\n",
    "def get_response(input_text,num_return_sequences,num_beams):\n",
    "  batch = tokenizer([input_text],truncation=True,padding=\"longest\",max_length=60, return_tensors=\"pt\").to(torch_device)\n",
    "  translated = model.generate(**batch,max_length=60,num_beams=num_beams, num_return_sequences=num_return_sequences, temperature=1.5)\n",
    "  tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "  return tgt_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The dinner was perfect.', \"Today's dinner was perfect.\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_beams = 100\n",
    "num_return_sequences = 2\n",
    "context = \"The today's dinner was perfect\"\n",
    "get_response(context,num_return_sequences,num_beams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': 'Model requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query.'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "model = \"TheBloke/Llama-2-70B-Chat-GPTQ\"\n",
    "\n",
    "API_URL = f\"https://api-inference.huggingface.co/models/{model}\"\n",
    "headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\n",
    "output = query({\n",
    "\t\"inputs\": \"Replace half of words with their synonyms in the following text:\\n  today is the good day! \",\n",
    "})\n",
    "\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
