{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9330231d",
   "metadata": {
    "papermill": {
     "duration": 0.009174,
     "end_time": "2024-04-23T20:04:21.181898",
     "exception": false,
     "start_time": "2024-04-23T20:04:21.172724",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DQN for text plagiarism detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0272e6f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T20:04:21.202028Z",
     "iopub.status.busy": "2024-04-23T20:04:21.201032Z",
     "iopub.status.idle": "2024-04-23T20:04:25.579755Z",
     "shell.execute_reply": "2024-04-23T20:04:25.579755Z"
    },
    "papermill": {
     "duration": 4.389355,
     "end_time": "2024-04-23T20:04:25.581807",
     "exception": false,
     "start_time": "2024-04-23T20:04:21.192452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "from functools import partial\n",
    "from typing import Literal, Protocol\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from cycler import cycler\n",
    "from torch.utils.data import Dataset\n",
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import GloVe\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4768c404",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T20:04:25.601433Z",
     "iopub.status.busy": "2024-04-23T20:04:25.601433Z",
     "iopub.status.idle": "2024-04-23T20:04:25.609792Z",
     "shell.execute_reply": "2024-04-23T20:04:25.608782Z"
    },
    "papermill": {
     "duration": 0.018965,
     "end_time": "2024-04-23T20:04:25.610823",
     "exception": false,
     "start_time": "2024-04-23T20:04:25.591858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EpsilonStrategy = Literal[\"cos\"] | Literal[\"line\"] | Literal[\"exp\"]\n",
    "\n",
    "\n",
    "class EpsilonCallable(Protocol):\n",
    "    def __call__(\n",
    "        self,\n",
    "        epoch: int,\n",
    "        epsilon_start: float,\n",
    "        epsilon_end: float,\n",
    "        last_epoch: int,\n",
    "        epsilon_const: float,\n",
    "    ) -> float:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df8a3cf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T20:04:25.629918Z",
     "iopub.status.busy": "2024-04-23T20:04:25.629918Z",
     "iopub.status.idle": "2024-04-23T20:04:25.654656Z",
     "shell.execute_reply": "2024-04-23T20:04:25.653645Z"
    },
    "papermill": {
     "duration": 0.037771,
     "end_time": "2024-04-23T20:04:25.657212",
     "exception": false,
     "start_time": "2024-04-23T20:04:25.619441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# DEVICE = torch.device(\"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "66b6791a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T20:04:25.676844Z",
     "iopub.status.busy": "2024-04-23T20:04:25.676844Z",
     "iopub.status.idle": "2024-04-23T20:04:25.679896Z",
     "shell.execute_reply": "2024-04-23T20:04:25.679896Z"
    },
    "papermill": {
     "duration": 0.01668,
     "end_time": "2024-04-23T20:04:25.681938",
     "exception": false,
     "start_time": "2024-04-23T20:04:25.665258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LOG_PATH_PREFIX = \"../logs/dqn/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae2230f",
   "metadata": {
    "papermill": {
     "duration": 0.008559,
     "end_time": "2024-04-23T20:04:25.702983",
     "exception": false,
     "start_time": "2024-04-23T20:04:25.694424",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db429cc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T20:04:25.728655Z",
     "iopub.status.busy": "2024-04-23T20:04:25.727648Z",
     "iopub.status.idle": "2024-04-23T20:04:25.734463Z",
     "shell.execute_reply": "2024-04-23T20:04:25.734463Z"
    },
    "papermill": {
     "duration": 0.022397,
     "end_time": "2024-04-23T20:04:25.736983",
     "exception": false,
     "start_time": "2024-04-23T20:04:25.714586",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "RL_GAMMA = 1.0\n",
    "\n",
    "GLOVE_DIM = 300\n",
    "TRAIN_SIZE = \"md\"\n",
    "TEST_SIZE = \"sm\"\n",
    "\n",
    "EMBED_DIM = GLOVE_DIM\n",
    "LSTM_LAYERS = 1\n",
    "LSTM_H_DIM = EMBED_DIM\n",
    "RNET_DROPOUT = 0.5\n",
    "\n",
    "ENV_GAMMA = 0.1\n",
    "\n",
    "DQN_LR = 0.005\n",
    "RNET_LR = 0.005\n",
    "SRM_LR = 0.005\n",
    "\n",
    "DQN_SYNC_PERIOD = 2\n",
    "DQN_CLIP_GRAD = 0.0\n",
    "\n",
    "PRETRAIN_SRM_RNET_EPOCHS = 200\n",
    "PRETRAIN_DQN_EPOCHS = 100\n",
    "\n",
    "EPISODES_BATCH = 10\n",
    "PRETRAIN_SRM_RNET_BATCH = EPISODES_BATCH\n",
    "\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_END = 0.01\n",
    "EPSILON_STRATEGY: EpsilonStrategy = \"cos\"\n",
    "EPSILON_CONSTANT = 50  # 1.4\n",
    "\n",
    "FEATURES = \"\"\n",
    "COMMENTS = \"\"\n",
    "\n",
    "EPOCHS = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "83ba46bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"23_04_2\"\n",
    "EPOCH = 1140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3c221b3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T20:04:25.848178Z",
     "iopub.status.busy": "2024-04-23T20:04:25.847166Z",
     "iopub.status.idle": "2024-04-23T20:04:25.865873Z",
     "shell.execute_reply": "2024-04-23T20:04:25.864861Z"
    },
    "papermill": {
     "duration": 0.049056,
     "end_time": "2024-04-23T20:04:25.870097",
     "exception": false,
     "start_time": "2024-04-23T20:04:25.821041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_from_experiments(experiment: str) -> None:\n",
    "    global \\\n",
    "        RL_GAMMA, \\\n",
    "        GLOVE_DIM, \\\n",
    "        TRAIN_SIZE, \\\n",
    "        TEST_SIZE, \\\n",
    "        EMBED_DIM, \\\n",
    "        LSTM_LAYERS, \\\n",
    "        LSTM_H_DIM, \\\n",
    "        RNET_DROPOUT, \\\n",
    "        ENV_GAMMA, \\\n",
    "        DQN_LR, \\\n",
    "        RNET_LR, \\\n",
    "        SRM_LR, \\\n",
    "        DQN_SYNC_PERIOD, \\\n",
    "        DQN_CLIP_GRAD, \\\n",
    "        PRETRAIN_SRM_RNET_EPOCHS, \\\n",
    "        PRETRAIN_DQN_EPOCHS, \\\n",
    "        EPISODES_BATCH, \\\n",
    "        PRETRAIN_SRM_RNET_BATCH, \\\n",
    "        EPSILON_START, \\\n",
    "        EPSILON_END, \\\n",
    "        EPSILON_STRATEGY, \\\n",
    "        EPSILON_CONSTANT, \\\n",
    "        FEATURES, \\\n",
    "        COMMENTS\n",
    "    with open(os.path.join(\".\", LOG_PATH_PREFIX, experiment, \"configs.json\"), \"r\") as f:\n",
    "        hyper_dict = json.load(f)\n",
    "    RL_GAMMA = hyper_dict[\"RL_GAMMA\"]\n",
    "\n",
    "    GLOVE_DIM = hyper_dict[\"GLOVE_DIM\"]\n",
    "    TRAIN_SIZE = hyper_dict[\"TRAIN_SIZE\"]\n",
    "    TEST_SIZE = hyper_dict[\"TEST_SIZE\"]\n",
    "    EMBED_DIM = hyper_dict[\"EMBED_DIM\"]\n",
    "    LSTM_LAYERS = hyper_dict[\"LSTM_LAYERS\"]\n",
    "    LSTM_H_DIM = hyper_dict[\"LSTM_H_DIM\"]\n",
    "    RNET_DROPOUT = hyper_dict[\"RNET_DROPOUT\"]\n",
    "    ENV_GAMMA = hyper_dict[\"ENV_GAMMA\"]\n",
    "    DQN_LR = hyper_dict[\"DQN_LR\"]\n",
    "    RNET_LR = hyper_dict[\"RNET_LR\"]\n",
    "    SRM_LR = hyper_dict[\"SRM_LR\"]\n",
    "    DQN_SYNC_PERIOD = hyper_dict[\"DQN_SYNC_PERIOD\"]\n",
    "    DQN_CLIP_GRAD = hyper_dict[\"DQN_CLIP_GRAD\"]\n",
    "    PRETRAIN_SRM_RNET_EPOCHS = hyper_dict[\"PRETRAIN_SRM_RNET_EPOCHS\"]\n",
    "    PRETRAIN_DQN_EPOCHS = hyper_dict[\"PRETRAIN_DQN_EPOCHS\"]\n",
    "    EPISODES_BATCH = hyper_dict[\"EPISODES_BATCH\"]\n",
    "    PRETRAIN_SRM_RNET_BATCH = hyper_dict[\"PRETRAIN_SRM_RNET_BATCH\"]\n",
    "    EPSILON_START = hyper_dict[\"EPSILON_START\"]\n",
    "    EPSILON_END = hyper_dict[\"EPSILON_END\"]\n",
    "    EPSILON_STRATEGY = hyper_dict[\"EPSILON_STRATEGY\"]\n",
    "    EPSILON_CONSTANT = hyper_dict[\"EPSILON_CONSTANT\"]\n",
    "    FEATURES = hyper_dict[\"FEATURES\"]\n",
    "    COMMENTS = hyper_dict[\"COMMENTS\"]\n",
    "    print(hyper_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6ce814",
   "metadata": {
    "papermill": {
     "duration": 0.009518,
     "end_time": "2024-04-23T20:04:25.901516",
     "exception": false,
     "start_time": "2024-04-23T20:04:25.891998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Epsilon Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3a88e853",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T20:04:25.944741Z",
     "iopub.status.busy": "2024-04-23T20:04:25.943737Z",
     "iopub.status.idle": "2024-04-23T20:04:25.951714Z",
     "shell.execute_reply": "2024-04-23T20:04:25.951052Z"
    },
    "papermill": {
     "duration": 0.021546,
     "end_time": "2024-04-23T20:04:25.952758",
     "exception": false,
     "start_time": "2024-04-23T20:04:25.931212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def epsilon_cos(\n",
    "    epoch: int,\n",
    "    epsilon_start: float,\n",
    "    epsilon_end: float,\n",
    "    last_epoch: int,\n",
    "    epsilon_const=50.0,\n",
    ") -> float:\n",
    "    return (\n",
    "        epsilon_start\n",
    "        * (np.cos(epsilon_const * epoch - epsilon_const) + 1)\n",
    "        * np.exp(-4 / last_epoch * (epoch - 1))\n",
    "        / 2\n",
    "    )\n",
    "\n",
    "\n",
    "def epsilon_line(\n",
    "    epoch: int,\n",
    "    epsilon_start: float,\n",
    "    epsilon_end: float,\n",
    "    last_epoch: int,\n",
    "    epsilon_const=20.0,\n",
    ") -> float:\n",
    "    return -np.emath.logn(\n",
    "        epsilon_const,\n",
    "        (\n",
    "            np.float_power(epsilon_const, -epsilon_start) * (epoch - last_epoch)\n",
    "            + np.float_power(epsilon_const, -epsilon_end) * (1 - epoch)\n",
    "        )\n",
    "        / (1 - last_epoch),\n",
    "    )\n",
    "\n",
    "\n",
    "def epsilon_exp(\n",
    "    epoch: int,\n",
    "    epsilon_start: float,\n",
    "    epsilon_end: float,\n",
    "    last_epoch: int,\n",
    "    epsilon_const: float = 1.4,\n",
    ") -> float:\n",
    "    return epsilon_start * np.exp(\n",
    "        np.log(epsilon_end / epsilon_start)\n",
    "        * epsilon_const\n",
    "        * (epoch - 1)\n",
    "        / (last_epoch - 1)\n",
    "    )\n",
    "\n",
    "\n",
    "EPSILON_STRATEGY_DICT: dict[EpsilonStrategy, EpsilonCallable] = {\n",
    "    \"cos\": epsilon_cos,\n",
    "    \"line\": epsilon_line,\n",
    "    \"exp\": epsilon_exp,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3b8463",
   "metadata": {
    "papermill": {
     "duration": 0.02867,
     "end_time": "2024-04-23T20:04:26.335495",
     "exception": false,
     "start_time": "2024-04-23T20:04:26.306825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "91d7798d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T20:04:26.447738Z",
     "iopub.status.busy": "2024-04-23T20:04:26.446858Z",
     "iopub.status.idle": "2024-04-23T20:04:26.490012Z",
     "shell.execute_reply": "2024-04-23T20:04:26.486971Z"
    },
    "papermill": {
     "duration": 0.112236,
     "end_time": "2024-04-23T20:04:26.497540",
     "exception": false,
     "start_time": "2024-04-23T20:04:26.385304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PREDEFINED_COLORS = [\n",
    "    \"#ffa500\",\n",
    "    \"#c83cbc\",\n",
    "    \"#1c1c84\",\n",
    "    \"#ff0000\",\n",
    "    \"#08a4a7\",\n",
    "    \"#008000\",\n",
    "]\n",
    "\n",
    "\n",
    "def get_plots(\n",
    "    data_dict: dict,\n",
    "    plots: list[tuple[dict, dict]],\n",
    "    title: str = \"\",\n",
    "    ylim=None,\n",
    "    row_plots: int = 1,\n",
    "    plot_width: float = 8,\n",
    "    plot_height: float = 4,\n",
    "    use_rainbow: bool = False,\n",
    "    use_common_legend: bool = False,\n",
    "    adjust: bool = False,\n",
    "):\n",
    "    num_plots = len(plots)\n",
    "    num_entities = max([len(x[1]) for x in plots]) + 1\n",
    "    if use_rainbow:\n",
    "        num_colors = num_entities\n",
    "        cm = plt.get_cmap(\"gist_rainbow\")\n",
    "        colors = [cm(1.0 * i / num_colors) for i in range(num_colors)]\n",
    "    else:\n",
    "        colors = PREDEFINED_COLORS\n",
    "\n",
    "    style_cycler = cycler(linestyle=[\"-\", \"--\", \":\", \"-.\"]) * cycler(color=colors)\n",
    "    column_plots = math.ceil(num_plots / row_plots)\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        column_plots,\n",
    "        row_plots,\n",
    "        figsize=(plot_width * row_plots, plot_height * column_plots),\n",
    "    )\n",
    "\n",
    "    if len(title) > 0:\n",
    "        fig.suptitle(title, fontsize=14, y=1)\n",
    "    axs_list = [axs] if column_plots * row_plots == 1 else list(axs.flat)\n",
    "\n",
    "    for ax in axs_list:\n",
    "        ax.grid()\n",
    "        ax.set_prop_cycle(style_cycler)\n",
    "        if ylim is not None:\n",
    "            ax.set_ylim(top=ylim)\n",
    "        ax.set_visible(False)\n",
    "\n",
    "    for ax, (p1, p2) in zip(axs_list, plots):\n",
    "        ax.set_visible(True)\n",
    "\n",
    "        ax.set_title(f\"{p2['axis_name']} over {p1['axis_name']}\")\n",
    "        ax.set(xlabel=p1[\"axis_label\"], ylabel=p2[\"axis_label\"])\n",
    "\n",
    "        if p1.get(\"log\", False):\n",
    "            ax.set_xscale(\"log\")\n",
    "        if p2.get(\"log\", False):\n",
    "            ax.set_yscale(\"log\")\n",
    "\n",
    "        x_values = data_dict[p1.get(\"ref\", None) or p1[\"axis_name\"]]\n",
    "\n",
    "        p2vs = p2.get(\"values\", [])\n",
    "        if len(p2vs) == 0:\n",
    "            y_values = data_dict[p2.get(\"ref\", None) or p2[\"axis_name\"]]\n",
    "            ax.plot(x_values, y_values, label=p2[\"axis_name\"])\n",
    "            ax.scatter(x_values[-1], y_values[-1], s=15)\n",
    "            continue\n",
    "\n",
    "        for p2v in p2vs:\n",
    "            y_values = data_dict[p2v.get(\"ref\", None) or p2v[\"name\"]]\n",
    "\n",
    "            try:\n",
    "                iter(y_values)\n",
    "                ax.plot(x_values, y_values, label=p2v[\"name\"])\n",
    "                ax.scatter(x_values[-1], y_values[-1], s=15)\n",
    "            except TypeError:\n",
    "                ax.plot(x_values, [y_values] * len(x_values), label=p2v[\"name\"])\n",
    "\n",
    "    if use_common_legend:\n",
    "        lines_labels = [axs_list[0].get_legend_handles_labels()]\n",
    "        lines, labels = [sum(x, []) for x in zip(*lines_labels)]\n",
    "        fig.legend(\n",
    "            lines,\n",
    "            labels,\n",
    "            scatterpoints=1,\n",
    "            markerscale=3,\n",
    "            loc=\"outside lower center\",\n",
    "            ncol=min(6, num_entities),\n",
    "            bbox_to_anchor=(0.5, -0.05),\n",
    "        )\n",
    "    else:\n",
    "        if num_entities > 1:\n",
    "            for ax, _ in zip(axs_list, plots):\n",
    "                ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if adjust:\n",
    "        plt.subplots_adjust(\n",
    "            top=1 - 0.1 / (num_plots**0.5), bottom=0.12 / (num_plots**2), hspace=0.15\n",
    "        )\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def draw_plots(\n",
    "    data_dict: dict,\n",
    "    plots: list[tuple[dict, dict]],\n",
    "    title: str = \"\",\n",
    "    ylim=None,\n",
    "    row_plots: int = 1,\n",
    "    plot_width: float = 8,\n",
    "    plot_height: float = 4,\n",
    "    use_rainbow: bool = False,\n",
    "    use_common_legend: bool = False,\n",
    "    adjust: bool = False,\n",
    "):\n",
    "    get_plots(\n",
    "        data_dict,\n",
    "        plots,\n",
    "        title,\n",
    "        ylim,\n",
    "        row_plots,\n",
    "        plot_width,\n",
    "        plot_height,\n",
    "        use_rainbow,\n",
    "        use_common_legend,\n",
    "        adjust,\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d907a94",
   "metadata": {
    "papermill": {
     "duration": 0.077521,
     "end_time": "2024-04-23T20:04:26.610267",
     "exception": false,
     "start_time": "2024-04-23T20:04:26.532746",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e81fe366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(name: str, model):\n",
    "    path = os.path.join(\n",
    "        \".\", LOG_PATH_PREFIX, EXPERIMENT_NAME, \"best\", str(EPOCH), \"models\", name\n",
    "    )\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e8fc9e",
   "metadata": {
    "papermill": {
     "duration": 0.043267,
     "end_time": "2024-04-23T20:04:27.025295",
     "exception": false,
     "start_time": "2024-04-23T20:04:26.982028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9cd6e480",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T20:04:27.148780Z",
     "iopub.status.busy": "2024-04-23T20:04:27.147782Z",
     "iopub.status.idle": "2024-04-23T20:04:32.465419Z",
     "shell.execute_reply": "2024-04-23T20:04:32.465419Z"
    },
    "papermill": {
     "duration": 5.358045,
     "end_time": "2024-04-23T20:04:32.470031",
     "exception": false,
     "start_time": "2024-04-23T20:04:27.111986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "global_vectors = GloVe(dim=GLOVE_DIM, cache=\"../data\")\n",
    "\n",
    "\n",
    "def text_pipeline(x):\n",
    "    return global_vectors.get_vecs_by_tokens(tokenizer(x), lower_case_backup=True)\n",
    "\n",
    "\n",
    "def tokenized_pipeline(x):\n",
    "    return global_vectors.get_vecs_by_tokens(x, lower_case_backup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "846f97d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T20:04:32.504546Z",
     "iopub.status.busy": "2024-04-23T20:04:32.502533Z",
     "iopub.status.idle": "2024-04-23T20:04:32.513105Z",
     "shell.execute_reply": "2024-04-23T20:04:32.512093Z"
    },
    "papermill": {
     "duration": 0.028026,
     "end_time": "2024-04-23T20:04:32.515101",
     "exception": false,
     "start_time": "2024-04-23T20:04:32.487075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_from_disk(path: str) -> np.ndarray:\n",
    "    return pd.read_csv(path).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ae517db4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T20:04:32.549386Z",
     "iopub.status.busy": "2024-04-23T20:04:32.548388Z",
     "iopub.status.idle": "2024-04-23T20:04:32.561525Z",
     "shell.execute_reply": "2024-04-23T20:04:32.560569Z"
    },
    "papermill": {
     "duration": 0.034384,
     "end_time": "2024-04-23T20:04:32.563520",
     "exception": false,
     "start_time": "2024-04-23T20:04:32.529136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PlagiarismDataset(Dataset):\n",
    "    def __init__(self, data: np.ndarray):\n",
    "        targets, candidates, scores = [], [], []\n",
    "\n",
    "        for target, candidate, score in data:\n",
    "            targets.append(tokenizer(target))\n",
    "            candidates.append(tokenizer(candidate))\n",
    "            scores.append(score)\n",
    "\n",
    "        self.targets = targets\n",
    "        self.candidates = candidates\n",
    "        self.scores = np.array(scores).astype(np.float16)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.scores)\n",
    "\n",
    "    def __getitem__(\n",
    "        self, idx\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor, list, list]:\n",
    "        return (\n",
    "            tokenized_pipeline(self.targets[idx]).to(DEVICE),\n",
    "            tokenized_pipeline(self.candidates[idx]).to(DEVICE),\n",
    "            torch.tensor([self.scores[idx]]).float().to(DEVICE),\n",
    "            self.targets[idx],\n",
    "            self.candidates[idx],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "931966ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T20:04:32.606938Z",
     "iopub.status.busy": "2024-04-23T20:04:32.605309Z",
     "iopub.status.idle": "2024-04-23T20:04:33.461880Z",
     "shell.execute_reply": "2024-04-23T20:04:33.458852Z"
    },
    "papermill": {
     "duration": 0.879048,
     "end_time": "2024-04-23T20:04:33.465879",
     "exception": false,
     "start_time": "2024-04-23T20:04:32.586831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(test_data)=147\n"
     ]
    }
   ],
   "source": [
    "test_data = PlagiarismDataset(\n",
    "    read_from_disk(f\"../generated/datasets/test_{TEST_SIZE}.csv\")\n",
    ")\n",
    "\n",
    "print(f\"{len(test_data)=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a8c439",
   "metadata": {
    "papermill": {
     "duration": 0.033685,
     "end_time": "2024-04-23T20:04:33.610794",
     "exception": false,
     "start_time": "2024-04-23T20:04:33.577109",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RNet & SRModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b161e689",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T20:04:33.758273Z",
     "iopub.status.busy": "2024-04-23T20:04:33.755610Z",
     "iopub.status.idle": "2024-04-23T20:04:33.788447Z",
     "shell.execute_reply": "2024-04-23T20:04:33.784919Z"
    },
    "papermill": {
     "duration": 0.105747,
     "end_time": "2024-04-23T20:04:33.794468",
     "exception": false,
     "start_time": "2024-04-23T20:04:33.688721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RNetNN(nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int, hidden_dim: int = 128) -> None:\n",
    "        super(RNetNN, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(RNET_DROPOUT),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class RNet:\n",
    "    def __init__(self, lr: float = 1e-2, device=DEVICE):\n",
    "        self.net = RNetNN(2 * LSTM_LAYERS * LSTM_H_DIM, 1).to(device)\n",
    "        self.loss_fn = F.mse_loss\n",
    "        self.optimizer = optim.Adam(\n",
    "            self.net.parameters(),\n",
    "            lr=lr,\n",
    "        )\n",
    "\n",
    "    def __call__(self, data: torch.Tensor, grad: bool = True) -> torch.Tensor:\n",
    "        if grad:\n",
    "            return self.net(data)\n",
    "        with torch.no_grad():\n",
    "            return self.net(data)\n",
    "\n",
    "\n",
    "class SRModelNN(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_dim: int, hidden_size: int, num_layers: int = LSTM_LAYERS\n",
    "    ) -> None:\n",
    "        super(SRModelNN, self).__init__()\n",
    "\n",
    "        self.net = nn.LSTM(\n",
    "            input_dim,\n",
    "            hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=False,\n",
    "        ).to(DEVICE)\n",
    "\n",
    "    def forward(self, *x):\n",
    "        return self.net(*x)\n",
    "\n",
    "\n",
    "class SRModel:\n",
    "    def __init__(self, lr: float = 1e-2, device=DEVICE):\n",
    "        self.net = SRModelNN(EMBED_DIM, LSTM_H_DIM).to(device)\n",
    "        self.optimizer = optim.Adam(\n",
    "            self.net.parameters(),\n",
    "            lr=lr,\n",
    "        )\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, *data, grad: bool = True) -> torch.Tensor:\n",
    "        if grad:\n",
    "            return self.net(*data)\n",
    "        with torch.no_grad():\n",
    "            return self.net(*data)\n",
    "\n",
    "    def call_batch(self, data, grad: bool = True) -> torch.Tensor:\n",
    "        cat_data = torch.cat(data) if type(data) == list else data\n",
    "        cat_data = cat_data.view(len(data), 1, -1)\n",
    "        h_c = (\n",
    "            torch.zeros(LSTM_LAYERS, 1, LSTM_H_DIM).to(self.device),\n",
    "            torch.zeros(LSTM_LAYERS, 1, LSTM_H_DIM).to(self.device),\n",
    "        )\n",
    "        out, _ = self.__call__(cat_data, h_c, grad=grad)\n",
    "        return out[-1].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5ab1bb59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T20:04:33.980287Z",
     "iopub.status.busy": "2024-04-23T20:04:33.979273Z",
     "iopub.status.idle": "2024-04-23T20:04:34.001927Z",
     "shell.execute_reply": "2024-04-23T20:04:33.997943Z"
    },
    "papermill": {
     "duration": 0.140474,
     "end_time": "2024-04-23T20:04:34.064833",
     "exception": false,
     "start_time": "2024-04-23T20:04:33.924359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_sample(\n",
    "    srm: SRModel,\n",
    "    rnet: RNet,\n",
    "    target: list[torch.Tensor],\n",
    "    candidate: list[torch.Tensor],\n",
    "    train_srm: bool = True,\n",
    "    train_rnet: bool = True,\n",
    "):\n",
    "    srm_out_target = srm.call_batch(target, train_srm)\n",
    "    srm_out_candidate = srm.call_batch(candidate, train_srm)\n",
    "\n",
    "    rnet_out = rnet(\n",
    "        torch.cat([srm_out_target, srm_out_candidate]).view(1, -1), grad=train_rnet\n",
    "    )\n",
    "\n",
    "    return rnet_out.squeeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb477e9a",
   "metadata": {
    "papermill": {
     "duration": 0.049989,
     "end_time": "2024-04-23T20:04:34.321869",
     "exception": false,
     "start_time": "2024-04-23T20:04:34.271880",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e27e3583",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T20:04:34.413425Z",
     "iopub.status.busy": "2024-04-23T20:04:34.412458Z",
     "iopub.status.idle": "2024-04-23T20:04:34.464565Z",
     "shell.execute_reply": "2024-04-23T20:04:34.462550Z"
    },
    "papermill": {
     "duration": 0.112137,
     "end_time": "2024-04-23T20:04:34.468565",
     "exception": false,
     "start_time": "2024-04-23T20:04:34.356428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Env:\n",
    "    def _get_state(self) -> torch.Tensor:\n",
    "        token = self.data[self.sentence_idx][self.token_idx]\n",
    "        return torch.cat(\n",
    "            [\n",
    "                self.hs[self.sentence_idx].flatten(),\n",
    "                self.cs[self.sentence_idx].flatten(),\n",
    "                token,\n",
    "            ]\n",
    "        ).to(DEVICE)\n",
    "\n",
    "    def _get_reward(self) -> float:\n",
    "        if not self.is_terminal():\n",
    "            return 0.0\n",
    "\n",
    "        self.statistics_dict[\"Deletions ratio\"] = (\n",
    "            self.statistics_dict[\"Deletions\"] / self.total_words\n",
    "        )\n",
    "\n",
    "        # Case when agent removes the entire sequence\n",
    "        if self.statistics_dict[\"Deletions\"] == self.total_words:\n",
    "            return 0.0\n",
    "\n",
    "        rnet_out = self.rnet(self.hs.view(1, -1), grad=False)\n",
    "\n",
    "        score_tensor = torch.FloatTensor([self.data[2]]).to(DEVICE)\n",
    "        loss = self.rnet.loss_fn(rnet_out.squeeze(-1), score_tensor)\n",
    "        self.loss = loss.item()\n",
    "\n",
    "        rnet_reward = np.log(1 - loss.item() + 1e-8)\n",
    "        deletions_reward = (\n",
    "            self.gamma * self.statistics_dict[\"Deletions\"] / self.total_words\n",
    "        )\n",
    "\n",
    "        self.statistics_dict[\"RNet reward\"] = rnet_reward\n",
    "        self.statistics_dict[\"Deletions reward\"] = deletions_reward\n",
    "\n",
    "        return rnet_reward + deletions_reward\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: Dataset,\n",
    "        srm: SRModel,\n",
    "        rnet: RNet,\n",
    "        gamma: float = ENV_GAMMA,\n",
    "        random_sampling: bool = True,\n",
    "    ) -> None:\n",
    "        self.srm = srm\n",
    "        self.rnet = rnet\n",
    "\n",
    "        self.gamma = gamma\n",
    "\n",
    "        self.dataset = dataset\n",
    "\n",
    "        self.random_sampling = random_sampling\n",
    "        self.idx = -1\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, idx: int = -1) -> torch.Tensor:\n",
    "        self.loss = -1\n",
    "\n",
    "        self.steps = 0\n",
    "\n",
    "        self.sentence_idx = 0\n",
    "        self.token_idx = 0\n",
    "\n",
    "        if self.random_sampling:\n",
    "            self.idx = np.random.randint(len(self.dataset))\n",
    "        elif idx >= 0:\n",
    "            self.idx = idx\n",
    "        else:\n",
    "            self.idx = (self.idx + 1) % len(self.dataset)\n",
    "\n",
    "        self.data = self.dataset[self.idx]\n",
    "\n",
    "        self.total_words = len(self.data[0]) + len(self.data[1])\n",
    "\n",
    "        self.hs = torch.zeros((2, LSTM_LAYERS, LSTM_H_DIM)).to(DEVICE)\n",
    "        self.cs = torch.zeros((2, LSTM_LAYERS, LSTM_H_DIM)).to(DEVICE)\n",
    "\n",
    "        self.used_tokens: tuple[list[torch.Tensor], list[torch.Tensor], float] = (\n",
    "            [],\n",
    "            [],\n",
    "            self.data[2].item(),\n",
    "        )\n",
    "\n",
    "        self.used_pure_tokens: tuple[list[str], list[str]] = ([], [])\n",
    "        self.deleted_tokens_dict = {}\n",
    "\n",
    "        self.statistics_dict = {\n",
    "            \"Initial Target length\": len(self.data[0]),\n",
    "            \"Initial Candidate length\": len(self.data[1]),\n",
    "            \"Processed Target length\": 0,\n",
    "            \"Processed Candidate length\": 0,\n",
    "            \"Deletions\": 0,\n",
    "            \"RNet reward\": 0.0,\n",
    "            \"Deletions reward\": 0.0,\n",
    "            \"Deletions ratio\": 0.0,\n",
    "        }\n",
    "\n",
    "        return self.get_state()\n",
    "\n",
    "    def get_state(self) -> torch.Tensor:\n",
    "        return self._get_state()\n",
    "\n",
    "    def is_terminal(self) -> bool:\n",
    "        return self.sentence_idx == 1 and self.token_idx == (len(self.data[1]) - 1)\n",
    "\n",
    "    def interact(self, action: int) -> tuple[torch.Tensor, float, bool]:\n",
    "        # 0 - retain\n",
    "        # 1 - delete\n",
    "\n",
    "        if self.is_terminal():\n",
    "            return self._get_state(), 0, self.is_terminal()\n",
    "\n",
    "        if action == 1:\n",
    "            self.statistics_dict[\"Deletions\"] += 1\n",
    "            pure_token = self.data[self.sentence_idx + 3][self.token_idx].lower()\n",
    "            self.deleted_tokens_dict[pure_token] = (\n",
    "                self.deleted_tokens_dict.get(pure_token, 0) + 1\n",
    "            )\n",
    "            self.used_pure_tokens[self.sentence_idx].append(\"DELETED\")\n",
    "\n",
    "        elif action == 0:\n",
    "            pure_token = self.data[self.sentence_idx + 3][self.token_idx].lower()\n",
    "            self.used_pure_tokens[self.sentence_idx].append(pure_token)\n",
    "\n",
    "            if self.sentence_idx == 0:\n",
    "                self.statistics_dict[\"Processed Target length\"] += 1\n",
    "            else:\n",
    "                self.statistics_dict[\"Processed Candidate length\"] += 1\n",
    "\n",
    "            token = self.data[self.sentence_idx][self.token_idx]\n",
    "            self.used_tokens[self.sentence_idx].append(  # type: ignore\n",
    "                token.clone().detach()\n",
    "            )\n",
    "\n",
    "            h_c = (\n",
    "                self.hs[self.sentence_idx].clone().detach(),\n",
    "                self.cs[self.sentence_idx].clone().detach(),\n",
    "            )\n",
    "\n",
    "            _, (h, c) = self.srm(token.view(1, -1), h_c, grad=False)\n",
    "            self.hs[self.sentence_idx] = h.clone().detach()\n",
    "            self.cs[self.sentence_idx] = c.clone().detach()\n",
    "\n",
    "        self.steps += 1\n",
    "        self.token_idx += 1\n",
    "        if self.sentence_idx == 0 and self.token_idx >= len(self.data[0]):\n",
    "            self.sentence_idx = 1\n",
    "            self.token_idx = 0\n",
    "\n",
    "        return self._get_state(), self._get_reward(), self.is_terminal()\n",
    "\n",
    "    def get_used_tokens(self) -> tuple[list[torch.Tensor], list[torch.Tensor], float]:\n",
    "        if len(self.used_tokens[0]) == 0:\n",
    "            self.used_tokens[0].append(torch.zeros(LSTM_LAYERS, LSTM_H_DIM).to(DEVICE))\n",
    "        if len(self.used_tokens[1]) == 0:\n",
    "            self.used_tokens[1].append(torch.zeros(LSTM_LAYERS, LSTM_H_DIM).to(DEVICE))\n",
    "        return self.used_tokens\n",
    "\n",
    "    def get_observation_shape(self) -> int:\n",
    "        return 2 * LSTM_LAYERS * LSTM_H_DIM + EMBED_DIM\n",
    "\n",
    "    def get_actions_shape(self) -> int:\n",
    "        return 2\n",
    "\n",
    "    @staticmethod\n",
    "    def sample_action() -> int:\n",
    "        return np.random.choice([0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f4e353",
   "metadata": {
    "papermill": {
     "duration": 0.034548,
     "end_time": "2024-04-23T20:04:34.550112",
     "exception": false,
     "start_time": "2024-04-23T20:04:34.515564",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DQN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7da68b81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T20:04:34.598118Z",
     "iopub.status.busy": "2024-04-23T20:04:34.597117Z",
     "iopub.status.idle": "2024-04-23T20:04:34.609194Z",
     "shell.execute_reply": "2024-04-23T20:04:34.607182Z"
    },
    "papermill": {
     "duration": 0.038085,
     "end_time": "2024-04-23T20:04:34.612197",
     "exception": false,
     "start_time": "2024-04-23T20:04:34.574112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int, hidden_dim: int = 16) -> None:\n",
    "        super(DQN, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dbd774",
   "metadata": {
    "papermill": {
     "duration": 0.02301,
     "end_time": "2024-04-23T20:04:34.664734",
     "exception": false,
     "start_time": "2024-04-23T20:04:34.641724",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "848aa48e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T20:04:34.846047Z",
     "iopub.status.busy": "2024-04-23T20:04:34.845036Z",
     "iopub.status.idle": "2024-04-23T20:04:34.859386Z",
     "shell.execute_reply": "2024-04-23T20:04:34.858374Z"
    },
    "papermill": {
     "duration": 0.168172,
     "end_time": "2024-04-23T20:04:34.863910",
     "exception": false,
     "start_time": "2024-04-23T20:04:34.695738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self) -> None:\n",
    "        epsilon_fc = EPSILON_STRATEGY_DICT[EPSILON_STRATEGY]\n",
    "        self.get_epsilon = partial(\n",
    "            epsilon_fc,\n",
    "            epsilon_start=EPSILON_START,\n",
    "            epsilon_end=EPSILON_END,\n",
    "            epsilon_const=EPSILON_CONSTANT,\n",
    "            last_epoch=EPOCHS,\n",
    "        )\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def choose_optimal_action(self, state: torch.Tensor, dqn: nn.Module) -> int:\n",
    "        q_vals_v = dqn(state)\n",
    "        act_v = torch.argmax(q_vals_v)\n",
    "        return int(act_v.item())\n",
    "\n",
    "    def choose_action(self, state: torch.Tensor, dqn: nn.Module, epoch: int) -> int:\n",
    "        if np.random.random() < self.get_epsilon(epoch):\n",
    "            return Env.sample_action()\n",
    "        return self.choose_optimal_action(state, dqn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee35aaec",
   "metadata": {
    "papermill": {
     "duration": 0.01754,
     "end_time": "2024-04-23T20:04:35.092555",
     "exception": false,
     "start_time": "2024-04-23T20:04:35.075015",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6a9191ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T20:04:35.141638Z",
     "iopub.status.busy": "2024-04-23T20:04:35.140640Z",
     "iopub.status.idle": "2024-04-23T20:04:35.163487Z",
     "shell.execute_reply": "2024-04-23T20:04:35.160945Z"
    },
    "papermill": {
     "duration": 0.054516,
     "end_time": "2024-04-23T20:04:35.169509",
     "exception": false,
     "start_time": "2024-04-23T20:04:35.114993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    srm: SRModel,\n",
    "    rnet: RNet,\n",
    "    dqn: nn.Module,\n",
    "    agent: Agent,\n",
    "    eval_env: Env,\n",
    ") -> tuple[list[str], list[str]]:\n",
    "    srm.net.eval()\n",
    "    rnet.net.eval()\n",
    "    dqn.eval()\n",
    "\n",
    "    total_len = len(eval_env.dataset)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    iteration = 0\n",
    "    state = eval_env.reset(0)\n",
    "\n",
    "    targets = []\n",
    "    candidates = []\n",
    "\n",
    "    with tqdm(total=total_len, desc=\"Evaluation\") as loop:\n",
    "        while iteration < total_len:\n",
    "            action = agent.choose_optimal_action(state, dqn)\n",
    "            state2, _, done = eval_env.interact(action)\n",
    "            state = state2.clone().detach()\n",
    "\n",
    "            if done:\n",
    "                iteration += 1\n",
    "                losses.append(eval_env.loss)\n",
    "\n",
    "                t, c = eval_env.used_pure_tokens\n",
    "                targets.append(t)\n",
    "                candidates.append(c)\n",
    "\n",
    "                state = eval_env.reset()\n",
    "\n",
    "                loop.update(1)\n",
    "\n",
    "    return targets, candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a5d602",
   "metadata": {
    "papermill": {
     "duration": 0.042756,
     "end_time": "2024-04-23T20:04:35.258018",
     "exception": false,
     "start_time": "2024-04-23T20:04:35.215262",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e4586fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean init target len = 38.65\n",
      "Mean init candidate len = 40.93\n"
     ]
    }
   ],
   "source": [
    "initial_targets, initial_candidates = zip(*[(x[3], x[4]) for x in test_data])\n",
    "\n",
    "itl = np.mean([len(x) for x in initial_targets])\n",
    "icl = np.mean([len(x) for x in initial_candidates])\n",
    "\n",
    "print(f\"Mean init target len = {itl:.2f}\")\n",
    "print(f\"Mean init candidate len = {icl:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "406d5fae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T20:04:35.364807Z",
     "iopub.status.busy": "2024-04-23T20:04:35.363817Z",
     "iopub.status.idle": "2024-04-23T20:04:35.397070Z",
     "shell.execute_reply": "2024-04-23T20:04:35.396057Z"
    },
    "papermill": {
     "duration": 0.0747,
     "end_time": "2024-04-23T20:04:35.404678",
     "exception": false,
     "start_time": "2024-04-23T20:04:35.329978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RL_GAMMA': 1.0, 'GLOVE_DIM': 300, 'TRAIN_SIZE': 'md', 'TEST_SIZE': 'sm', 'EMBED_DIM': 300, 'LSTM_LAYERS': 1, 'LSTM_H_DIM': 300, 'RNET_DROPOUT': 0.5, 'ENV_GAMMA': 0.1, 'DQN_LR': 0.005, 'RNET_LR': 0.005, 'SRM_LR': 0.005, 'DQN_SYNC_PERIOD': 2, 'DQN_CLIP_GRAD': 0.0, 'PRETRAIN_SRM_RNET_EPOCHS': 200, 'PRETRAIN_DQN_EPOCHS': 100, 'EPISODES_BATCH': 10, 'PRETRAIN_SRM_RNET_BATCH': 10, 'EPSILON_START': 1.0, 'EPSILON_END': 0.01, 'EPSILON_STRATEGY': 'cos', 'EPSILON_CONSTANT': 50, 'FEATURES': '', 'COMMENTS': ''}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_from_experiments(EXPERIMENT_NAME)\n",
    "\n",
    "rnet = RNet(lr=RNET_LR)\n",
    "srm = SRModel(lr=SRM_LR)\n",
    "\n",
    "env = Env(test_data, srm, rnet, random_sampling=False)\n",
    "agent = Agent()\n",
    "\n",
    "dqn_net = DQN(\n",
    "    input_dim=env.get_observation_shape(), output_dim=env.get_actions_shape()\n",
    ").to(DEVICE)\n",
    "dqn_target_net = DQN(\n",
    "    input_dim=env.get_observation_shape(), output_dim=env.get_actions_shape()\n",
    ").to(DEVICE)\n",
    "\n",
    "\n",
    "load_model(\"dqn\", dqn_net)\n",
    "load_model(\"rnet\", rnet.net)\n",
    "load_model(\"srm\", srm.net)\n",
    "\n",
    "dqn_target_net.load_state_dict(dqn_net.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0c3768c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 147/147 [00:10<00:00, 13.72it/s]\n"
     ]
    }
   ],
   "source": [
    "targets, candidates = evaluate(srm, rnet, dqn_net, agent, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "61d910c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean target len = 27.56 | 11.09 ~ 28.69% deleted\n",
      "Mean candidate len = 27.78 | 13.16 ~ 32.14% deleted\n"
     ]
    }
   ],
   "source": [
    "tl = np.mean([len([w for w in x if w != \"DELETED\"]) for x in targets])\n",
    "cl = np.mean([len([w for w in x if w != \"DELETED\"]) for x in candidates])\n",
    "\n",
    "print(f\"Mean target len = {tl:.2f} | {itl-tl:.2f} ~ {100-tl/itl*100:.2f}% deleted\")\n",
    "print(f\"Mean candidate len = {cl:.2f} | {icl-cl:.2f} ~ {100-cl/icl*100:.2f}% deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5380fabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (it, t) in enumerate(zip(initial_targets, targets)):\n",
    "    print(idx, \" \".join(it))\n",
    "    print(idx, \" \".join(t))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a94609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (it, t) in enumerate(zip(initial_candidates, candidates)):\n",
    "    print(idx, \" \".join(it))\n",
    "    print(idx, \" \".join(t))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af70614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets: 37,\n",
    "# candidates: 51,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb31ff5",
   "metadata": {},
   "source": [
    "## Custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8287e686",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_data = PlagiarismDataset(\n",
    "    [(\" \".join(initial_targets[10]), \"the\", 0)],\n",
    ")\n",
    "\n",
    "custom_env = Env(custom_data, srm, rnet, random_sampling=False)\n",
    "\n",
    "c_targets, _ = evaluate(srm, rnet, dqn_net, agent, custom_env)\n",
    "c_targets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2401.302006,
   "end_time": "2024-04-23T20:44:18.625533",
   "environment_variables": {},
   "exception": null,
   "input_path": "./3.2-dqn.ipynb",
   "output_path": "./3.2-dqn.ipynb",
   "parameters": {
    "EPOCHS": 1500,
    "EVAL_PERIOD": 10,
    "EXPERIMENT_NAME": "23_04_2",
    "LOG_PERIOD": 10
   },
   "start_time": "2024-04-23T20:04:17.323527",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
